{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Preparation ===\n",
      "Total samples: 810\n",
      "Number of classes: 5\n",
      "CSV shape: (2430, 8)\n",
      "True labels aligned: First 5 samples = [0 1 4 1 1]\n",
      "\n",
      "=== Model Probabilities ===\n",
      "DenseNet169:\n",
      "  Shape: (810, 5)\n",
      "InceptionV3:\n",
      "  Shape: (810, 5)\n",
      "Xception:\n",
      "  Shape: (810, 5)\n",
      "\n",
      "=== Fuzzy Ensembling Results ===\n",
      "First 5 predicted classes: [0 0 4 1 1]\n",
      "\n",
      "=== Performance Evaluation ===\n",
      "Classification Report:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            im_Dyskeratotic       0.91      0.93      0.92       163\n",
      "            im_Koilocytotic       0.87      0.85      0.86       165\n",
      "             im_Metaplastic       0.89      0.89      0.89       159\n",
      "               im_Parabasal       0.92      0.91      0.92       157\n",
      "im_Superficial-Intermediate       0.98      0.98      0.98       166\n",
      "\n",
      "                   accuracy                           0.91       810\n",
      "                  macro avg       0.91      0.91      0.91       810\n",
      "               weighted avg       0.91      0.91      0.91       810\n",
      "\n",
      "\n",
      "=== Files Saved ===\n",
      "Predictions saved to: /content/ensemble_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load combined probabilities from CSV\n",
    "combined_csv_path = 'all_probabilities_1.csv'\n",
    "prob_df = pd.read_csv(combined_csv_path)\n",
    "\n",
    "# Class labels\n",
    "class_labels = ['im_Dyskeratotic', 'im_Koilocytotic', 'im_Metaplastic',\n",
    "                'im_Parabasal', 'im_Superficial-Intermediate']\n",
    "num_classes = len(class_labels)  # 5\n",
    "num_samples = len(prob_df) // 3  # Assuming each model has predictions for all samples\n",
    "\n",
    "# --- Data Preparation ---\n",
    "print(\"=== Data Preparation ===\")\n",
    "print(f\"Total samples: {num_samples}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"CSV shape: {prob_df.shape}\")\n",
    "\n",
    "# Extract true labels directly from CSV\n",
    "true_classes_from_csv = prob_df['True_Label'].unique()\n",
    "if isinstance(true_classes_from_csv[0], str):  # If labels are strings, encode them\n",
    "    le = LabelEncoder()\n",
    "    le.fit(class_labels)\n",
    "    true_classes = le.transform(prob_df['True_Label'].iloc[:num_samples].values)\n",
    "else:\n",
    "    true_classes = prob_df['True_Label'].iloc[:num_samples].values\n",
    "\n",
    "print(f\"True labels aligned: First 5 samples = {true_classes[:5]}\")\n",
    "\n",
    "# --- Model Probabilities ---\n",
    "print(\"\\n=== Model Probabilities ===\")\n",
    "model_probs = {}\n",
    "for model_name in ['DenseNet169', 'InceptionV3', 'Xception']:\n",
    "    model_df = prob_df[prob_df['Model'] == model_name].iloc[:num_samples]\n",
    "    probs = model_df[class_labels].values\n",
    "    model_probs[model_name] = probs\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Shape: {probs.shape}\")\n",
    "\n",
    "# --- Fuzzy Ensembling ---\n",
    "print(\"\\n=== Fuzzy Ensembling Results ===\")\n",
    "def expo_equ(probs):\n",
    "    return 1 - np.exp(-((probs - 1) ** 2) / 2)\n",
    "\n",
    "def tanh_equ(probs):\n",
    "    return 1 - np.tanh(((probs - 1) ** 2) / 2)\n",
    "def norm_equ(probs):\n",
    "    return 1 / (1 + np.exp(-probs))\n",
    "def compute_final_score(probs):\n",
    "    return expo_equ(probs) * tanh_equ(probs) * norm_equ(probs)\n",
    "\n",
    "# Step 1: Compute membership scores for each model\n",
    "model_scores = {model: compute_final_score(model_probs[model]) for model in model_probs}\n",
    "\n",
    "# Step 2: Sum membership scores across models\n",
    "ensemble_class_scores = np.zeros((num_samples, num_classes))\n",
    "for model_name in model_scores:\n",
    "    ensemble_class_scores += model_scores[model_name]\n",
    "\n",
    "# Step 3: Predict classes based on summed scores\n",
    "ensemble_predicted_classes = np.argmin(ensemble_class_scores, axis=1)\n",
    "print(f\"First 5 predicted classes: {ensemble_predicted_classes[:5]}\")\n",
    "\n",
    "# --- Performance Evaluation ---\n",
    "print(\"\\n=== Performance Evaluation ===\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_classes, ensemble_predicted_classes, target_names=class_labels))\n",
    "\n",
    "# --- Save Results ---\n",
    "ensemble_df = pd.DataFrame({\n",
    "    'True_Label': true_classes,\n",
    "    'Predicted_Label': ensemble_predicted_classes\n",
    "})\n",
    "ensemble_df.to_csv('ensemble_predictions.csv', index=False)\n",
    "print(\"\\n=== Files Saved ===\")\n",
    "print(\"Predictions saved to: /content/ensemble_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Preparation ===\n",
      "Total samples: 810\n",
      "Number of classes: 5\n",
      "CSV shape: (2430, 8)\n",
      "True labels aligned: First 5 samples = [0 1 4 1 1]\n",
      "\n",
      "=== Model Probabilities ===\n",
      "DenseNet169:\n",
      "  Shape: (810, 5)\n",
      "InceptionV3:\n",
      "  Shape: (810, 5)\n",
      "Xception:\n",
      "  Shape: (810, 5)\n",
      "\n",
      "=== Fuzzy Ensembling Results ===\n",
      "First 5 predicted classes: [0 0 4 1 1]\n",
      "\n",
      "=== Performance Evaluation ===\n",
      "Classification Report:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            im_Dyskeratotic       0.91      0.93      0.92       163\n",
      "            im_Koilocytotic       0.86      0.85      0.86       165\n",
      "             im_Metaplastic       0.89      0.89      0.89       159\n",
      "               im_Parabasal       0.92      0.91      0.91       157\n",
      "im_Superficial-Intermediate       0.98      0.98      0.98       166\n",
      "\n",
      "                   accuracy                           0.91       810\n",
      "                  macro avg       0.91      0.91      0.91       810\n",
      "               weighted avg       0.91      0.91      0.91       810\n",
      "\n",
      "\n",
      "=== Files Saved ===\n",
      "Predictions saved to: /content/ensemble_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load combined probabilities from CSV\n",
    "combined_csv_path = 'all_probabilities_1.csv'\n",
    "prob_df = pd.read_csv(combined_csv_path)\n",
    "\n",
    "# Class labels\n",
    "class_labels = ['im_Dyskeratotic', 'im_Koilocytotic', 'im_Metaplastic',\n",
    "                'im_Parabasal', 'im_Superficial-Intermediate']\n",
    "num_classes = len(class_labels)  # 5\n",
    "num_samples = len(prob_df) // 3  # Assuming each model has predictions for all samples\n",
    "\n",
    "# --- Data Preparation ---\n",
    "print(\"=== Data Preparation ===\")\n",
    "print(f\"Total samples: {num_samples}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"CSV shape: {prob_df.shape}\")\n",
    "\n",
    "# Extract true labels directly from CSV\n",
    "true_classes_from_csv = prob_df['True_Label'].unique()\n",
    "if isinstance(true_classes_from_csv[0], str):  # If labels are strings, encode them\n",
    "    le = LabelEncoder()\n",
    "    le.fit(class_labels)\n",
    "    true_classes = le.transform(prob_df['True_Label'].iloc[:num_samples].values)\n",
    "else:\n",
    "    true_classes = prob_df['True_Label'].iloc[:num_samples].values\n",
    "\n",
    "print(f\"True labels aligned: First 5 samples = {true_classes[:5]}\")\n",
    "\n",
    "# --- Model Probabilities ---\n",
    "print(\"\\n=== Model Probabilities ===\")\n",
    "model_probs = {}\n",
    "for model_name in ['DenseNet169', 'InceptionV3', 'Xception']:\n",
    "    model_df = prob_df[prob_df['Model'] == model_name].iloc[:num_samples]\n",
    "    probs = model_df[class_labels].values\n",
    "    model_probs[model_name] = probs\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Shape: {probs.shape}\")\n",
    "\n",
    "# --- Fuzzy Ensembling ---\n",
    "print(\"\\n=== Fuzzy Ensembling Results ===\")\n",
    "def expo_equ(probs):\n",
    "    return 1 - np.exp(-((probs - 1) ** 2) / 2)\n",
    "\n",
    "def tanh_equ(probs):\n",
    "    return 1 - np.tanh(((probs - 1) ** 2) / 2)\n",
    "def norm_equ(probs):\n",
    "    return 1 / (1 + np.exp(-probs))\n",
    "def compute_final_score(probs):\n",
    "    return expo_equ(probs) * norm_equ(probs)\n",
    "\n",
    "# Step 1: Compute membership scores for each model\n",
    "model_scores = {model: compute_final_score(model_probs[model]) for model in model_probs}\n",
    "\n",
    "# Step 2: Sum membership scores across models\n",
    "ensemble_class_scores = np.zeros((num_samples, num_classes))\n",
    "for model_name in model_scores:\n",
    "    ensemble_class_scores += model_scores[model_name]\n",
    "\n",
    "# Step 3: Predict classes based on summed scores\n",
    "ensemble_predicted_classes = np.argmin(ensemble_class_scores, axis=1)\n",
    "print(f\"First 5 predicted classes: {ensemble_predicted_classes[:5]}\")\n",
    "\n",
    "# --- Performance Evaluation ---\n",
    "print(\"\\n=== Performance Evaluation ===\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_classes, ensemble_predicted_classes, target_names=class_labels))\n",
    "\n",
    "# --- Save Results ---\n",
    "ensemble_df = pd.DataFrame({\n",
    "    'True_Label': true_classes,\n",
    "    'Predicted_Label': ensemble_predicted_classes\n",
    "})\n",
    "ensemble_df.to_csv('ensemble_predictions.csv', index=False)\n",
    "print(\"\\n=== Files Saved ===\")\n",
    "print(\"Predictions saved to: /content/ensemble_predictions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Data Preparation ===\n",
      "Total samples: 810\n",
      "Number of classes: 5\n",
      "CSV shape: (2430, 8)\n",
      "True labels aligned: First 5 samples = [0 1 4 1 1]\n",
      "\n",
      "=== Model Probabilities ===\n",
      "DenseNet169:\n",
      "  Shape: (810, 5)\n",
      "InceptionV3:\n",
      "  Shape: (810, 5)\n",
      "Xception:\n",
      "  Shape: (810, 5)\n",
      "\n",
      "=== Fuzzy Ensembling Results ===\n",
      "First 5 predicted classes: [4 4 3 4 3]\n",
      "\n",
      "=== Performance Evaluation ===\n",
      "Classification Report:\n",
      "                             precision    recall  f1-score   support\n",
      "\n",
      "            im_Dyskeratotic       0.00      0.00      0.00     163.0\n",
      "            im_Koilocytotic       0.00      0.00      0.00     165.0\n",
      "             im_Metaplastic       0.00      0.00      0.00     159.0\n",
      "               im_Parabasal       0.00      0.00      0.00     157.0\n",
      "im_Superficial-Intermediate       0.00      0.00      0.00     166.0\n",
      "\n",
      "                   accuracy                           0.00     810.0\n",
      "                  macro avg       0.00      0.00      0.00     810.0\n",
      "               weighted avg       0.00      0.00      0.00     810.0\n",
      "\n",
      "\n",
      "=== Files Saved ===\n",
      "Predictions saved to: /content/ensemble_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load combined probabilities from CSV\n",
    "combined_csv_path = 'all_probabilities_1.csv'\n",
    "prob_df = pd.read_csv(combined_csv_path)\n",
    "\n",
    "# Class labels\n",
    "class_labels = ['im_Dyskeratotic', 'im_Koilocytotic', 'im_Metaplastic',\n",
    "                'im_Parabasal', 'im_Superficial-Intermediate']\n",
    "num_classes = len(class_labels)  # 5\n",
    "num_samples = len(prob_df) // 3  # Assuming each model has predictions for all samples\n",
    "\n",
    "# --- Data Preparation ---\n",
    "print(\"=== Data Preparation ===\")\n",
    "print(f\"Total samples: {num_samples}\")\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "print(f\"CSV shape: {prob_df.shape}\")\n",
    "\n",
    "# Extract true labels directly from CSV\n",
    "true_classes_from_csv = prob_df['True_Label'].unique()\n",
    "if isinstance(true_classes_from_csv[0], str):  # If labels are strings, encode them\n",
    "    le = LabelEncoder()\n",
    "    le.fit(class_labels)\n",
    "    true_classes = le.transform(prob_df['True_Label'].iloc[:num_samples].values)\n",
    "else:\n",
    "    true_classes = prob_df['True_Label'].iloc[:num_samples].values\n",
    "\n",
    "print(f\"True labels aligned: First 5 samples = {true_classes[:5]}\")\n",
    "\n",
    "# --- Model Probabilities ---\n",
    "print(\"\\n=== Model Probabilities ===\")\n",
    "model_probs = {}\n",
    "for model_name in ['DenseNet169', 'InceptionV3', 'Xception']:\n",
    "    model_df = prob_df[prob_df['Model'] == model_name].iloc[:num_samples]\n",
    "    probs = model_df[class_labels].values\n",
    "    model_probs[model_name] = probs\n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"  Shape: {probs.shape}\")\n",
    "\n",
    "# --- Fuzzy Ensembling ---\n",
    "print(\"\\n=== Fuzzy Ensembling Results ===\")\n",
    "def expo_equ(probs):\n",
    "    return 1 - np.exp(-((probs - 1) ** 2) / 2)\n",
    "\n",
    "def tanh_equ(probs):\n",
    "    return 1 - np.tanh(((probs - 1) ** 2) / 2)\n",
    "def norm_equ(probs):\n",
    "    return 1 / (1 + np.exp(-probs))\n",
    "def compute_final_score(probs):\n",
    "    return tanh_equ(probs) * norm_equ(probs)\n",
    "\n",
    "# Step 1: Compute membership scores for each model\n",
    "model_scores = {model: compute_final_score(model_probs[model]) for model in model_probs}\n",
    "\n",
    "# Step 2: Sum membership scores across models\n",
    "ensemble_class_scores = np.zeros((num_samples, num_classes))\n",
    "for model_name in model_scores:\n",
    "    ensemble_class_scores += model_scores[model_name]\n",
    "\n",
    "# Step 3: Predict classes based on summed scores\n",
    "ensemble_predicted_classes = np.argmin(ensemble_class_scores, axis=1)\n",
    "print(f\"First 5 predicted classes: {ensemble_predicted_classes[:5]}\")\n",
    "\n",
    "# --- Performance Evaluation ---\n",
    "print(\"\\n=== Performance Evaluation ===\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(true_classes, ensemble_predicted_classes, target_names=class_labels))\n",
    "\n",
    "# --- Save Results ---\n",
    "ensemble_df = pd.DataFrame({\n",
    "    'True_Label': true_classes,\n",
    "    'Predicted_Label': ensemble_predicted_classes\n",
    "})\n",
    "ensemble_df.to_csv('ensemble_predictions.csv', index=False)\n",
    "print(\"\\n=== Files Saved ===\")\n",
    "print(\"Predictions saved to: /content/ensemble_predictions.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
